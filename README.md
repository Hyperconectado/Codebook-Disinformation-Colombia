# Codebook-Disinformation-Colombia
Marco de referencia para análisis de fenómenos de desinformación en Colombia.

| Categoría | Definición |
| --------- | ---------- |
| Misinformation | Difusión involuntaria de información falsa.  No existe intención de engañar.  En algunos casos alguien toma una "Disinformation" sin saber que es falsa y la comparte. En ese caso es Misinformation.  |
| Disinformation | Creación y difusión voluntaria de información falsa que busca crear daño o generar problemas. En algunos casos específicos la "Disinformation" cuando se comparte se puede categorizar como "misinformation". En esta categoría pueden estar afirmaciones prejuiciosas. Afirmaciones parciales, con una inclinación.  (Biased claims)  |
| Malinformation | Información real que busca dañar una persona, institución o comunidad.  Ejemplo: Compartir una historia médica real para afectar reputación de alguien.  |
| Sátira o Parodia | Uso del ridículo, burla, ironía, parodia o caricatura para narrar un hecho social.  El problema de la satira en el contexto de la desinformación es que tiene potencial para engañar.  Sátira debería considerarse una forma de arte. Sin embargo, es usado para difundir rumores o conspiraciones. Muchas veces lo que se comparte categorizado como sátira es en realidad discurso de odio. Por ejemplo: Cuentas que usan el calificativo de sátira pero comparten contenido político de injurias o calumnias.    
| Conexión Falsa | Cuando el titular, mensaje o la foto no corresponden al desarrollo del contenido. Ejemplo: La imagen miniatura del video ([thumbnail](https://en.wikipedia.org/wiki/Thumbnail)) muestra el rostro de Rigoberto Urán y Egan Bernal. El video corresponde a otro tema no relacionado ni con el titular ni con la miniatura del video. Por ejemplo: [Video en YouTube](https://www.youtube.com/watch?v=itrDwdH2e0Q)  <img width="867" alt="image" src="https://github.com/Hyperconectado/Codebook-Disinformation-Colombia/assets/506051/b0aad28e-477b-43df-bfd9-d2e3e637a390">|
| Contenido Engañoso | Contenido que busca soportar un punto de vista que en la mayoría de los casos no es una realidad comprobable y que busca un beneficio propio. Puede presentarse en muchas formas. Técnicas usadas: Uso de citas parciales, manipulación de estadísticas, creación de enfoques engañosos de una noticia, omitir Información Por ejemplo: Creación de mapa con información incompleta que busca dar la idea de que Colombia hizo un giro a la derecha en las elecciones de 2023. [Post en X](https://twitter.com/CamiloSilvaJ/status/1719072970230931930)  |
| Contexto Falso | Tomar un video, foto, cita o hecho para cambiar su significado con el objetivo de causar daño. Por ejemplo: [Post en X](https://www.instagram.com/p/CyMj9lTr-if/?hl=es) y [Post en X](https://x.com/DavidRacero/status/1711566065535201439?s=20?) |
| Contenido de Impostor | Contenido que usa identificaciones o logos pero que realmente no fue producido a quien se le atribuye. [Mensaje de medio de comunicación afectado por impostor](https://twitter.com/kienyke/status/1715479738569949663?) |
| Contenido Manipulado | Contenido original que es cambiado o transformado con la intención de engañar [Niño disfrazado de guerrillero](https://www.youtube.com/watch?v=_cC3ZmP5lnM&t=16s) |
| Contenido Fabricado | Creación de contenido 100% falso. [Video en YouTube](https://www.youtube.com/shorts/jdR3DuDFB4I) |
| Clickbaiting | Técnica usada para atraer usuarios sin tener en cuenta las consideraciones éticas y profesionales de una publicación. Su objetivo es alcanzar un alto volumen de usuarios visitando un portal. Por ejemplo: [Pulzo](https://www.pulzo.com/nacion/gustavo-petro-no-terminara-mandato-colombia-prediccion-astrologa-PP3116102) |
| Error Involuntario | Difusión de una noticia cuya intención no fue el engaño. Anomalía en la construcción de la pieza informativa genera su clasificación. Por ejemplo: En este texto se observan dos datos diferentes acerca de las cifras de formalización de tierras en Colombia. El Espectador nota la diferencia y crea un artículo explicando el fenómeno. [Link en el Espectador](https://www.elespectador.com/politica/cifras-de-formalizacion-de-tierras-avivan-pulso-entre-jhenifer-mojica-y-gerardo-vega-min-agricultura-ant-noticias-colombia/ ) |
| Posible Desinformación | Descripción con tono editorial que califique y describa una posible desinformación. Descripción corta creada por un profesional y que califica o evalua la posible desinformación. |
| URL  | Link donde se detectó   |
| Intento de Debuking o Aclaración | Publicaciones donde se intentó desmentir o se añadió información profesional sobre el tema. |
| Comentarios | Información adicional sobre la explicación. Puede incluir links para sustentar la explicación. |
| Plataforma | Servicio tecnológico que se usó para publicar. Facebook, X, Instagram, Tik Tok, Reddit, Telegram, Whastapp, Kwai. |
| Medio de Comunicación | Medio masivo tradicional o no tradicional. |
| Tipo de Medio | Radio, Televisión, Digital, Prensa. |
| Primera Publicación: URL | Solo se añade en casos donde se hace el trabajo de ubicar la fuente original por razones técnicas. |
| Título de la publicación | Si existe. En el sentido periodístico del concepto titular. Mensaje enviado en Twitter, Facebook. Texto que acompaña el mensaje. |
| Fecha de Detección | Día, mes, año |
| Hora Detección |   |
| Fecha de Publicación | Día, mes año |
| Hora Publicación |  |
| Narrativa Principal | Son categorías de temas generales. (Aún no se crean las categorías)  |
| Descripción de la Narrativa | Cada categoría tiene varias subcategorias. (Aún no se crean)  |
| Motivo | Qué intenta lograr la desinformación : Ganancia, Político, Ataque a instituciones  |
| Keywords | Tres palabras claves para identificar el tema. |
| Actor que crea el contenido | Actor individual, Actor Político, Compañía , Medio, Bot, Cyborg. |

## Referencias
1. Wardle, Claire, and Hossein Derakhshan. "Information Disorder: Toward an interdisciplinary framework for research and policy making." Council of Europe Report 27 (2017).
2. Samikshya Siwakoti, Isra Thange, Anne Wen, Prof. Shapiro. COVID Misinformation Codebook V3.0. ESOC COVID-19 Misinformation Dataset.
3. Samantha Bradshaw, University of Oxford, Philip N. Howard, University of Oxford. Troops, Trolls and Troublemakers: A Global Inventory of Organized Social Media Manipulation.
4. Dr. Joan Donovan. Technology and Social Change Project at the Harvard Kennedy School Shorenstein Center for Media, Politics, and Public Policy.The Media Manipulation Casebook. Code Book.
5. Whitney Phillips. The Oxygen of Amplification Better Practices for Reporting on Extremists, Antagonists, and Manipulators
6. Emerson T. Brooking, Alyssa Kann, & Max Rizzuto. Digital Forensic Research Lab, Atlantic Council. Dichotomies of Disinformation: Project Overview & Codebook













